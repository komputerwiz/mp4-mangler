\chapter{Introduction}
\label{cha:introduction}

Video media pervades modern life: it captures memories of important events, keeps records for later review, tells engaging stories for entertainment, and spreads news about current events. Much of this video data has great intrinsic or sentimental value and is worth preserving. Yet, some videos succumb to data corruption over time and eventually lose their ability to be viewed. Digital video files are saved in many different formats. At the time of writing, MPEG-4 (MP4 for short) is one of the most common formats, and a preliminary survey shows it is particularly susceptible to this type of corruption and loss. This study investigates the underlying cause of this problem.

\section{Background}

Digital forensics, as the subject implies, brings the rigor of forensic investigation to digital applications. Any forensic science seeks to answer the question, ``What happened here?'' usually in the wake of some unknown or undesirable event such as a criminal investigation. Digital forensics frequently involves working with data assumed to contain valuable information, but that information may not be known ahead of time and must be uncovered through analysis and interpretation. Low-level sequences of bits stored in a computer may seem like random noise on initial inspection. These bits derive meaning from how they are interpreted, which, in turn, depends on the method used to encode the information they represent. The loss of this critical metadata might result in the effective loss of the data itself, akin to losing the key needed to decrypt a secure message. More fundamentally, even if the proper decoding method is known, the resulting interpretation is potentially meaningless if the data itself is corrupted.

Within the realm of digital forensics, data recovery methods provide a means of detecting and repairing data corruption or reverse engineering its interpretation. However, such \emph{a posteriori} methods come into use only after the damage has been done. The task of hardening data against corruption or aiding in recovery \emph{a priori} belongs to the field of data preservation. Both of these fields complement each other: improvements to data preservation tactics amplify the effectiveness of data recovery methods, and advances in data recovery improve the perceived reliability of current data formats and storage practices. 

Media information collectively refers to audio, photographic, and video information. Encoding such information into files poses a particular challenge due to its complexity. By contrast, numeric and textual information can be encoded efficiently in compact formats that are relatively easy for both humans and computers to interpret. This is due to the symbolic nature of text and numbers, where information is conveyed through discrete finite values and glyphs. Media data carries much more information and is intended to reconstruct the signals that stimulate our senses directly. Consider the nature of this data. Our senses and the mind's interpretation leave much room for the data to vary: two similar-looking videos might have subtle variations in subject placement, colors, brightness, audio, timing, etc. While there is significant room for variation, media formats represent a form of ordered information that is distinct from randomness. Note the virtual impossibility that any such meaningful patterns could emerge from truly random data (e.g., white noise and ``snow''). The combination of variation and non-randomness in this information implies a large amount of entropy and, therefore, a large amount of bandwidth required to encode it.

Media data are also highly dimensional, depending on the type. Audio data consists of a sequence of channels oriented along a single time dimension. Photographic media consists of color channels within a two-dimensional pixel array and reconstructs a visual stimulus at a single point in time. Video data is particularly interesting because it is a combination of both, with two-dimensional photographic data drawn out over time and usually accompanied by parallel audio data. If left in their raw formats, such video data would occupy an inordinate amount of storage space; so audio and visual \emph{codecs} employ various compression methods to retain the original meaning or value of the data while reducing the amount of space required to store it. Some codecs are perfectly reversible and therefore \emph{lossless}, whereas others represent an approximation of the original data and discard the residuals---i.e., \emph{lossy} codecs.

Codecs encode a single stream of either audio or visual information, but not both. Therefore, to represent a video as a single file unit, the file format must contain a combination of encoded audio and visual \emph{streams} related by a common timescale. These file formats are called \emph{containers}. At the time of writing, MPEG-4 Part 14 (MP4), Matroska (MKV), and WebM (a derivative of MKV) represent some commonly used video container formats, with MP4 being highly favored by a vast majority of available hardware and software. Each container format supports one or more codecs for storing each contained audio and video stream. In the case of MP4, the most often used audio and video codecs are AAC and H.264, respectively. The Advanced Audio Coding (AAC) codec was first standardized in MPEG-2 Part 7, and the Advanced Video Coding (H.264) codec was introduced in MPEG-4 Part 10. Focusing on these most popular formats limits the scope of research while maximizing relevance to the general public.

\section{The MP4 Container Format}

\subsection{Specification History}

The specifications governing the MP4 file format have their origin in Apple's QuickTime File Format (QTFF), which was originally published in 2001 \cite{apple2001}. This format was standardized and promulgated in ISO/IEC 14496-1 \cite{iso14496-1:2001} later that year by the Moving Picture Experts Group (MPEG) \cite{mpeg}\footnote{The MPEG group has since been closed in favor of the \emph{Moving Picture, Audio, and Data Coding by Artificial Intelligence (MPAI)} community \cite{mpai}.}. Since then, the format has been refined and updated to give rise to the following current standards:
\begin{itemize}
	\item ISO/IEC 14496-12:2022 -- ISO base media file format \cite{iso14496-12:2022},
	\item ISO/IEC 14496-14:2020 -- MP4 file format \cite{iso14496-14:2020}, and
	\item ISO/IEC 14496-15:2022 -- Carriage of network abstraction layer (NAL) unit structured video in the ISO base media file format \cite{iso14496-15:2022}.
\end{itemize}
14496-12 defines the basic structure used by the MP4 file format, and then 14496-14 extends this basic structure to include additional support specifically for certain audio and video codecs. The contents of 14496-15 are beyond the scope of this study.

It should be noted that these official standards are not freely available: each publication costs 208 CHF (232.96 USD) to purchase at the time of writing. However, the specification can be obtained in other ways. The MPEG website archive \cite{mpeg} provides older, withdrawn versions of each publication, while Apple maintains the current version of the QTFF specification on its website with the following notice:
\begin{quote}
	The QTFF has been used as the basis of the MPEG-4 standard and the JPEG-2000 standard, developed by the International Organization for Standardization (ISO). Although these file types have similar structures and contain many functionally identical elements, they are distinct file types. \cite{apple2016}
\end{quote}
Despite the claim that the file types are distinct, the two file format specifications are similar enough from a technical perspective to develop a tool capable of reading files in either format. The structure of the MP4 file format can also be learned by inspecting the source code of open-source software that is capable of opening MP4 files, such as VLC \footnote{\url{https://www.videolan.org/vlc/}}, MPV \footnote{\url{https://mpv.io/}}, and ffmpeg \footnote{\url{https://ffmpeg.org/}}, to name a few.

\subsection{Basic Internal Structure}

Internally, an MP4 file contains a composite hierarchy of data units arranged as a tree. Apple's QTFF Specification \cite{apple2016} refers to these as ``atoms,'' whereas the ISO/IEC MPEG-4 specification refers to these as ``boxes.'' The two definitions are practically identical, and the terms may be used interchangeably in this document. However, the latter will be preferred out of respect for the standard, even though the information presented here relies heavily on Apple's freely available specification instead of the paywall-restricted ISO/IEC specification.

Each box consists of a header and contents. The header includes a 4-byte discriminant value that helps to determine the type of data that the box contains. This discriminant, in combination with the box's position within the tree (i.e., ``ancestor'' boxes and their types), determines the exact field structure of a box. Apple gives the following example in their specification: ``the \emph{profile} atom inside a \emph{movie} atom contains information about the movie, while the \emph{profile} atom inside a \emph{track} atom contains information about the track'' (emphasis added to denote types). Given the above general description, all boxes contain at least the following two, maybe three, basic header fields in the provided order:

\begin{enumerate}
	\item \texttt{size}: \emph{unsigned 32-bit integer}, the number of bytes that the whole box occupies, including these fields. There are two special cases for this value:
		\begin{enumerate}
			\item The root box (and \emph{only the root}) may contain a size of 0 if its contents continue until the end of the file.
			\item A box whose size is over \( 2^{32} \) bytes in length will have a size of 1 and provide the actual size in an additional \texttt{extended size} field below.
		\end{enumerate}
	\item \texttt{type}: \emph{4-character string}, the box's type discriminant.
	\item \texttt{extended size}: \emph{unsigned 64-bit integer (optional)}, this field is present only if it is larger than what can fit in the \texttt{size} field. Otherwise, it is either omitted or filled with a placeholder \texttt{wide} box.\footnote{A \texttt{wide} box is an ``empty'' box containing only a header with a \texttt{size} of 8 bytes and a type of \texttt{"wide"}. Filling the extended size with a \texttt{wide} box has the effect of allowing the box to grow larger than \( 2^{32} \) bytes without needing to rewrite or reallocate it.}
\end{enumerate}

Of the many types of boxes defined by the specification, the following types are of interest: \texttt{moov} and \texttt{mdat}. A movie file must contain a \texttt{moov} box because it contains metadata about the movie and how to interpret it. Such metadata includes the number of tracks in the file, the type (audio, video, subtitles, etc.), codec used, and time synchronization information for each track, references for converting time indices to data locations, etc. The data referenced by the \texttt{moov} is stored in \texttt{mdat} boxes elsewhere in the file and not in the \texttt{moov} box itself. \texttt{mdat} boxes are relatively simple: each contains a header with the \texttt{size}, a \texttt{type} of \texttt{mdat}, and optionally the \texttt{extended size}, followed directly by binary media data. The structure of a \texttt{moov} box is much more complicated, but it is sufficient to note that its presence and integrity are vital to the file's playability.

Atoms deeper within the \texttt{moov} hierarchy are more tightly coupled with the individual pieces of the data that comprise the media information. For example, The \texttt{dinf} atom indicates where the data resides, i.e. the current file itself or in an external file, and the \texttt{stbl} atom provides a mapping from time and sample number to the offset/address where the sample's data can be found. According to the QTTF specification, ``a sample is a single element in a sequence of time-ordered data,'' the quantum of data represented by an MP4 container.

\section{Problem Statement}

The MP4 video file format is susceptible to data corruption. The degree to which this corruption affects the encoded video varies greatly. In some cases, minor corruption may have little to no effect. Noticeable effects may consist of a benign reduction in media quality or alter the video in some way. These types of errors leave the file in a still-playable state and sometimes can be recovered to their original quality using existing video recovery methods. However, in some unfortunate cases, even small amounts of data corruption in the right (or wrong) place can render an entire MP4 video file unplayable even though the vast remainder of the file remains intact.

The goal of this report is to investigate and document how data corruption can lead to unplayable MP4 video files. This process may happen naturally over time without any human intervention, unintentionally through user error, or purposefully for some intended (possibly malicious) reason. Nonetheless, we hypothesize that a simple, common underlying mechanism exists by which MP4 videos are rendered unplayable. Namely, the destruction of critical data within the MP4 file.